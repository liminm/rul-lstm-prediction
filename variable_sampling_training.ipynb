{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543ff77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_pad(batch: List[Tuple[torch.Tensor, float, int]]):\n",
    "    seqs, targets, lengths = zip(*batch)\n",
    "\n",
    "    lengths_t = torch.tensor(lengths, dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True)\n",
    "    targets_t = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    return padded.float(), lengths_t, targets_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b160e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import CmapssRandomCropDataset\n",
    "\n",
    "def make_loader(sequences_by_unit, rul_by_unit, samples_per_epoch, batch_size, l_min, l_max, num_workers=0):\n",
    "    ds = CmapssRandomCropDataset(\n",
    "        sequences_by_unit=sequences_by_unit,\n",
    "        rul_by_unit=rul_by_unit,\n",
    "        samples_per_epoch=samples_per_epoch,\n",
    "        l_min=l_min,\n",
    "        l_max=l_max,\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_pad,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2421d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_rul(model, seq: torch.Tensor, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "\n",
    "    if seq.dim() != 2:\n",
    "        raise ValueError(\"Expected seq shape [L, F]\")\n",
    "\n",
    "    padded = seq.unsqueeze(0).to(device).float()\n",
    "    lengths = torch.tensor([seq.shape[0]], dtype=torch.long, device=device)\n",
    "\n",
    "    pred = model(padded, lengths)[0].item()\n",
    "    return float(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6075c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for padded, lengths, targets in loader:\n",
    "        padded = padded.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(padded, lengths)\n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = targets.shape[0]\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / max(n, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c58ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416b7661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_nr', 'time_cycles', 'setting_1', 'setting_2', 'setting_3', 's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n",
      "Train data shape: (20631, 30)\n",
      "Test data shape: (13096, 28)\n",
      "RUL labels shape: (100, 1)\n",
      "len train ids: 80\n",
      "len val ids: 20\n",
      "len engine ids: 100\n",
      "Train df shape: (16138, 30)\n",
      "Val df shape: (4493, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The dataset has 26 columns\n",
    "# 1. Unit Number (Which engine is it?)\n",
    "# 2. Time Cycles (How long has it been running?)\n",
    "# 3-5. Operational Settings (Altitude, Speed, etc.)\n",
    "# 6-26. Sensor Readings (s1 to s21)\n",
    "\n",
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1, 22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "print(col_names)\n",
    "\n",
    "def load_fd(fd_tag):\n",
    "    train_path = f\"data/train_{fd_tag}.txt\"\n",
    "    test_path  = f\"data/test_{fd_tag}.txt\"\n",
    "    rul_path   = f\"data/RUL_{fd_tag}.txt\"\n",
    "\n",
    "    raw_train_df = pd.read_csv(train_path, sep=r'\\s+', header=None, names=col_names)\n",
    "    raw_test_df  = pd.read_csv(test_path,  sep=r'\\s+', header=None, names=col_names)\n",
    "    raw_rul_labels_df = pd.read_csv(rul_path, header=None, names=['RUL_truth'])\n",
    "\n",
    "    # train labels: compute RUL from run-to-failure\n",
    "    max_cycle = raw_train_df.groupby('unit_nr')['time_cycles'].max().rename('max_cycle')\n",
    "    raw_train_df = raw_train_df.merge(max_cycle, left_on='unit_nr', right_index=True)\n",
    "    raw_train_df['RUL'] = raw_train_df['max_cycle'] - raw_train_df['time_cycles']\n",
    "\n",
    "    # test labels: provided separately\n",
    "    return raw_train_df, raw_test_df, raw_rul_labels_df\n",
    "\n",
    "next_unit = 1\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "test_rul_labels = []\n",
    "\n",
    "data_tags = [\"FD001\",\"FD002\",\"FD003\",\"FD004\"]\n",
    "data_tags = [\"FD001\"]\n",
    "\n",
    "for fd_tag in data_tags:\n",
    "    train_df_chunk, test_df_chunk, rul_labels_chunk = load_fd(fd_tag)\n",
    "    train_df_chunk['fd'] = fd_tag\n",
    "    test_df_chunk['fd'] = fd_tag\n",
    "    test_df_chunk = test_df_chunk.assign(\n",
    "        unit_nr_orig=test_df_chunk['unit_nr'],\n",
    "        unit_nr=test_df_chunk['unit_nr'] + next_unit - 1\n",
    "    )\n",
    "    test_dfs.append(test_df_chunk)\n",
    "    test_rul_labels.append(rul_labels_chunk)\n",
    "\n",
    "    # make a mapping for this FD's units\n",
    "    uniq_units = sorted(train_df_chunk['unit_nr'].unique())\n",
    "    mapping = {u: next_unit + i for i, u in enumerate(uniq_units)}\n",
    "    next_unit += len(uniq_units)\n",
    "\n",
    "    train_df_chunk = train_df_chunk.assign(\n",
    "        unit_nr_orig=train_df_chunk['unit_nr'],\n",
    "        unit_nr=train_df_chunk['unit_nr'].map(mapping),\n",
    "        fd=fd_tag\n",
    "    )\n",
    "    train_dfs.append(train_df_chunk)\n",
    "    \n",
    "    \n",
    "data_df = pd.concat(train_dfs, ignore_index=True)\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "rul_labels_df = pd.concat(test_rul_labels, ignore_index=True)\n",
    "\n",
    "print(f\"Train data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"RUL labels shape: {rul_labels_df.shape}\")\n",
    "\n",
    "engine_ids = train_df['unit_nr'].unique()\n",
    "\n",
    "train_ids = engine_ids[:80]\n",
    "val_ids = engine_ids[80:]\n",
    "print(\"len train ids:\", len(train_ids))\n",
    "print(\"len val ids:\", len(val_ids))\n",
    "print(\"len engine ids:\", len(engine_ids))\n",
    "\n",
    "train_split_df = train_df[train_df['unit_nr'].isin(train_ids)]\n",
    "val_split_df = train_df[train_df['unit_nr'].isin(val_ids)]\n",
    "print(\"Train df shape:\", train_split_df.shape)\n",
    "print(\"Val df shape:\", val_split_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2ed57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale: ['setting_1', 'setting_2', 'setting_3', 's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456647</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.425154</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.725482</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606936</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.473456</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.732001</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.248555</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.386193</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.619473</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537572</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.267715</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.661565</td>\n",
       "      <td>188</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.269082</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.704790</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "0        1            1   0.456647   0.166667        0.0  0.0  0.183735   \n",
       "1        1            2   0.606936   0.250000        0.0  0.0  0.283133   \n",
       "2        1            3   0.248555   0.750000        0.0  0.0  0.343373   \n",
       "3        1            4   0.537572   0.500000        0.0  0.0  0.343373   \n",
       "4        1            5   0.387283   0.333333        0.0  0.0  0.349398   \n",
       "\n",
       "        s_3       s_4  s_5  ...      s_14      s_15  s_16      s_17  s_18  \\\n",
       "0  0.425154  0.309757  0.0  ...  0.199608  0.363986   0.0  0.363636   0.0   \n",
       "1  0.473456  0.352633  0.0  ...  0.162813  0.411312   0.0  0.363636   0.0   \n",
       "2  0.386193  0.370527  0.0  ...  0.171793  0.357445   0.0  0.181818   0.0   \n",
       "3  0.267715  0.331195  0.0  ...  0.174889  0.166603   0.0  0.363636   0.0   \n",
       "4  0.269082  0.404625  0.0  ...  0.174734  0.402078   0.0  0.454545   0.0   \n",
       "\n",
       "   s_19      s_20      s_21  RUL  max_cycle  \n",
       "0   0.0  0.708661  0.725482  191        192  \n",
       "1   0.0  0.661417  0.732001  190        192  \n",
       "2   0.0  0.622047  0.619473  189        192  \n",
       "3   0.0  0.566929  0.661565  188        192  \n",
       "4   0.0  0.582677  0.704790  187        192  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "not_scaled_cols = ['unit_nr', 'RUL', 'max_cycle', 'time_cycles']\n",
    "\n",
    "col_set = set(col_names)\n",
    "columns_to_scale = [col for col in col_names if col not in not_scaled_cols]\n",
    "\n",
    "print(\"Columns to scale:\", columns_to_scale)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_split = scaler.fit_transform(train_split_df[columns_to_scale])\n",
    "scaled_train_split_df = pd.DataFrame(scaled_train_split, columns=columns_to_scale, index=train_split_df.index)\n",
    "scaled_val_split = scaler.transform(val_split_df[columns_to_scale])\n",
    "scaled_val_split_df = pd.DataFrame(scaled_val_split, columns=columns_to_scale, index=val_split_df.index)\n",
    "\n",
    "scaled_train_split_df.insert(0, 'unit_nr', train_split_df['unit_nr'])\n",
    "scaled_train_split_df.insert(1, 'time_cycles', train_split_df['time_cycles'])\n",
    "scaled_train_split_df.insert(len(scaled_train_split_df.columns), 'RUL', train_split_df['RUL'])\n",
    "scaled_train_split_df.insert(len(scaled_train_split_df.columns), 'max_cycle', train_split_df['max_cycle'])\n",
    "\n",
    "scaled_val_split_df.insert(0, 'unit_nr', val_split_df['unit_nr'])\n",
    "scaled_val_split_df.insert(1, 'time_cycles', val_split_df['time_cycles'])\n",
    "scaled_val_split_df.insert(len(scaled_val_split_df.columns), 'RUL', val_split_df['RUL'])\n",
    "scaled_val_split_df.insert(len(scaled_val_split_df.columns), 'max_cycle', val_split_df['max_cycle'])\n",
    "\n",
    "scaled_train_split_df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b35874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16138 entries, 0 to 16137\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   unit_nr      16138 non-null  int64  \n",
      " 1   time_cycles  16138 non-null  int64  \n",
      " 2   setting_1    16138 non-null  float64\n",
      " 3   setting_2    16138 non-null  float64\n",
      " 4   setting_3    16138 non-null  float64\n",
      " 5   s_1          16138 non-null  float64\n",
      " 6   s_2          16138 non-null  float64\n",
      " 7   s_3          16138 non-null  float64\n",
      " 8   s_4          16138 non-null  float64\n",
      " 9   s_5          16138 non-null  float64\n",
      " 10  s_6          16138 non-null  float64\n",
      " 11  s_7          16138 non-null  float64\n",
      " 12  s_8          16138 non-null  float64\n",
      " 13  s_9          16138 non-null  float64\n",
      " 14  s_10         16138 non-null  float64\n",
      " 15  s_11         16138 non-null  float64\n",
      " 16  s_12         16138 non-null  float64\n",
      " 17  s_13         16138 non-null  float64\n",
      " 18  s_14         16138 non-null  float64\n",
      " 19  s_15         16138 non-null  float64\n",
      " 20  s_16         16138 non-null  float64\n",
      " 21  s_17         16138 non-null  float64\n",
      " 22  s_18         16138 non-null  float64\n",
      " 23  s_19         16138 non-null  float64\n",
      " 24  s_20         16138 non-null  float64\n",
      " 25  s_21         16138 non-null  float64\n",
      " 26  RUL          16138 non-null  int64  \n",
      " 27  max_cycle    16138 non-null  int64  \n",
      "dtypes: float64(24), int64(4)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "scaled_train_split_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab20815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4493 entries, 16138 to 20630\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   unit_nr      4493 non-null   int64  \n",
      " 1   time_cycles  4493 non-null   int64  \n",
      " 2   setting_1    4493 non-null   float64\n",
      " 3   setting_2    4493 non-null   float64\n",
      " 4   setting_3    4493 non-null   float64\n",
      " 5   s_1          4493 non-null   float64\n",
      " 6   s_2          4493 non-null   float64\n",
      " 7   s_3          4493 non-null   float64\n",
      " 8   s_4          4493 non-null   float64\n",
      " 9   s_5          4493 non-null   float64\n",
      " 10  s_6          4493 non-null   float64\n",
      " 11  s_7          4493 non-null   float64\n",
      " 12  s_8          4493 non-null   float64\n",
      " 13  s_9          4493 non-null   float64\n",
      " 14  s_10         4493 non-null   float64\n",
      " 15  s_11         4493 non-null   float64\n",
      " 16  s_12         4493 non-null   float64\n",
      " 17  s_13         4493 non-null   float64\n",
      " 18  s_14         4493 non-null   float64\n",
      " 19  s_15         4493 non-null   float64\n",
      " 20  s_16         4493 non-null   float64\n",
      " 21  s_17         4493 non-null   float64\n",
      " 22  s_18         4493 non-null   float64\n",
      " 23  s_19         4493 non-null   float64\n",
      " 24  s_20         4493 non-null   float64\n",
      " 25  s_21         4493 non-null   float64\n",
      " 26  RUL          4493 non-null   int64  \n",
      " 27  max_cycle    4493 non-null   int64  \n",
      "dtypes: float64(24), int64(4)\n",
      "memory usage: 1017.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>max_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.429938</td>\n",
       "      <td>0.411546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179792</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.608560</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16139</th>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630058</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.346548</td>\n",
       "      <td>0.432647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208639</td>\n",
       "      <td>0.509427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>0.620890</td>\n",
       "      <td>238</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16140</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>0.468208</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403614</td>\n",
       "      <td>0.350422</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.489804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.643282</td>\n",
       "      <td>237</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16141</th>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491329</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361446</td>\n",
       "      <td>0.543404</td>\n",
       "      <td>0.381668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227991</td>\n",
       "      <td>0.444017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16142</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.443153</td>\n",
       "      <td>0.461344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.277799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.600907</td>\n",
       "      <td>235</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_nr  time_cycles  setting_1  setting_2  setting_3  s_1       s_2  \\\n",
       "16138       81            1   0.208092   0.750000        0.0  0.0  0.250000   \n",
       "16139       81            2   0.630058   0.666667        0.0  0.0  0.433735   \n",
       "16140       81            3   0.468208   0.916667        0.0  0.0  0.403614   \n",
       "16141       81            4   0.491329   0.500000        0.0  0.0  0.361446   \n",
       "16142       81            5   0.635838   0.666667        0.0  0.0  0.662651   \n",
       "\n",
       "            s_3       s_4  s_5  ...      s_14      s_15  s_16      s_17  s_18  \\\n",
       "16138  0.429938  0.411546  0.0  ...  0.179792  0.464025   0.0  0.272727   0.0   \n",
       "16139  0.346548  0.432647  0.0  ...  0.208639  0.509427   0.0  0.363636   0.0   \n",
       "16140  0.350422  0.238859  0.0  ...  0.205439  0.489804   0.0  0.545455   0.0   \n",
       "16141  0.543404  0.381668  0.0  ...  0.227991  0.444017   0.0  0.363636   0.0   \n",
       "16142  0.443153  0.461344  0.0  ...  0.202652  0.277799   0.0  0.363636   0.0   \n",
       "\n",
       "       s_19      s_20      s_21  RUL  max_cycle  \n",
       "16138   0.0  0.559055  0.608560  239        240  \n",
       "16139   0.0  0.590551  0.620890  238        240  \n",
       "16140   0.0  0.692913  0.643282  237        240  \n",
       "16141   0.0  0.480315  0.727749  236        240  \n",
       "16142   0.0  0.692913  0.600907  235        240  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_val_split_df.info()\n",
    "scaled_val_split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90, 24]) 12.0 90\n",
      "torch.Size([32, 140, 24]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([32, 158, 24]) torch.Size([32]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "sequences_by_unit = {}\n",
    "rul_by_unit = {}\n",
    "\n",
    "feature_cols = col_names[2:]  # Exclude 'unit_nr' and 'time_cycles'\n",
    "\n",
    "import torch\n",
    "\n",
    "def build_unit_dicts(df, feature_cols):\n",
    "    sequences_by_unit = {}\n",
    "    rul_by_unit = {}\n",
    "\n",
    "    df = df.sort_values([\"unit_nr\", \"time_cycles\"])\n",
    "\n",
    "    for unit_id, g in df.groupby(\"unit_nr\", sort=False):\n",
    "        x = torch.tensor(g[feature_cols].to_numpy(), dtype=torch.float32)\n",
    "        y = torch.tensor(g[\"RUL\"].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "        sequences_by_unit[int(unit_id)] = x\n",
    "        rul_by_unit[int(unit_id)] = y\n",
    "\n",
    "    return sequences_by_unit, rul_by_unit\n",
    "\n",
    "train_sequences_by_unit, train_rul_by_unit = build_unit_dicts(scaled_train_split_df, feature_cols)\n",
    "val_sequences_by_unit, val_rul_by_unit = build_unit_dicts(scaled_val_split_df, feature_cols)\n",
    "\n",
    "from dataset import CmapssRandomCropDataset\n",
    "\n",
    "dataset = CmapssRandomCropDataset(\n",
    "    sequences_by_unit=train_sequences_by_unit,\n",
    "    rul_by_unit=train_rul_by_unit,\n",
    "    samples_per_epoch=1000,\n",
    "    l_min=30,\n",
    "    l_max=100,\n",
    ")\n",
    "\n",
    "seq, target, length = dataset[0]  # or dataset[42], same behavior\n",
    "print(seq.shape, target, length)\n",
    "\n",
    "train_loader = make_loader(train_sequences_by_unit, train_rul_by_unit, samples_per_epoch=10000, batch_size=32, l_min=30, l_max=200)\n",
    "padded, lengths, targets = next(iter(train_loader))\n",
    "print(padded.shape, lengths.shape, targets.shape)\n",
    "\n",
    "val_loader = make_loader(val_sequences_by_unit, val_rul_by_unit, samples_per_epoch=8000, batch_size=32, l_min=30, l_max=200)\n",
    "padded, lengths, targets = next(iter(val_loader))\n",
    "print(padded.shape, lengths.shape, targets.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80607537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "def train_full(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    last_epoch_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        n = 0\n",
    "        epoch_loss = 0\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        for padded, lengths, targets in loader:\n",
    "            padded = padded.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(padded, lengths)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            bs = targets.shape[0]\n",
    "            total_loss += loss.item() * bs\n",
    "            total_samples += bs\n",
    "            epoch_loss += loss.item()\n",
    "            n += bs\n",
    "        \n",
    "        epoch_mean_loss = total_loss / max(total_samples, 1)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} total loss: {total_loss:.4f}, mean loss: {epoch_mean_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        #with torch.no_grad():\n",
    "        #    preds = model()\n",
    "\n",
    "\n",
    "        latest_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1a6f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_full() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m model.to(device)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#loss = train_one_epoch(model, dataset_loader, optimizer, device)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m loss = \u001b[43mtrain_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: train_full() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "from model import RulLstm\n",
    "\n",
    "\n",
    "model = RulLstm(\n",
    "    n_features=len(feature_cols),\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "\n",
    "#loss = train_one_epoch(model, dataset_loader, optimizer, device)\n",
    "\n",
    "loss = train_full(model, train_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1078abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def run_epoch(model, loader, loss_fn, device, train: bool, optimizer=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    if train:\n",
    "        context = torch.enable_grad()\n",
    "    else:\n",
    "        context = torch.no_grad()\n",
    "\n",
    "    with context:\n",
    "        for padded, lengths, targets in loader:\n",
    "            padded = padded.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(padded, lengths)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            bs = targets.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_samples += bs\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "    return total_loss / max(total_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4cd92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "def train_full(model, train_loader, val_loader, optimizer, device):\n",
    "    loss_fn = nn.SmoothL1Loss(reduction=\"mean\")\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = run_epoch(\n",
    "            model=model,\n",
    "            loader=train_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "            train=True,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "        val_loss = run_epoch(\n",
    "            model=model,\n",
    "            loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "            train=False,\n",
    "            optimizer=None,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{EPOCHS} \"\n",
    "            f\"train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8dd232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/20 train_loss: 32.8874 | val_loss: 30.1581\n",
      "Epoch 2/20 train_loss: 26.5449 | val_loss: 30.2501\n",
      "Epoch 3/20 train_loss: 19.0747 | val_loss: 18.5627\n",
      "Epoch 4/20 train_loss: 12.2974 | val_loss: 14.6034\n",
      "Epoch 5/20 train_loss: 10.1090 | val_loss: 12.8112\n",
      "Epoch 6/20 train_loss: 9.5594 | val_loss: 12.4224\n",
      "Epoch 7/20 train_loss: 9.2045 | val_loss: 11.4218\n",
      "Epoch 8/20 train_loss: 8.9363 | val_loss: 11.5449\n",
      "Epoch 9/20 train_loss: 8.7233 | val_loss: 11.8341\n",
      "Epoch 10/20 train_loss: 8.7024 | val_loss: 12.4358\n",
      "Epoch 11/20 train_loss: 8.5117 | val_loss: 11.9647\n",
      "Epoch 12/20 train_loss: 8.5177 | val_loss: 11.4252\n",
      "Epoch 13/20 train_loss: 8.2313 | val_loss: 11.0311\n",
      "Epoch 14/20 train_loss: 8.0163 | val_loss: 11.1253\n",
      "Epoch 15/20 train_loss: 8.0923 | val_loss: 10.9845\n",
      "Epoch 16/20 train_loss: 8.1057 | val_loss: 10.9642\n",
      "Epoch 17/20 train_loss: 7.8929 | val_loss: 10.9441\n",
      "Epoch 18/20 train_loss: 7.9647 | val_loss: 11.4296\n",
      "Epoch 19/20 train_loss: 7.8910 | val_loss: 10.1145\n",
      "Epoch 20/20 train_loss: 7.8613 | val_loss: 11.1915\n"
     ]
    }
   ],
   "source": [
    "from model import RulLstm\n",
    "\n",
    "\n",
    "model = RulLstm(\n",
    "    n_features=len(feature_cols),\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "\n",
    "#loss = train_one_epoch(model, dataset_loader, optimizer, device)\n",
    "\n",
    "loss = train_full(model, train_loader, val_loader, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-lstm-next-frame-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
